{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6181d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-generativeai in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (0.8.5)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from google-generativeai) (0.6.15)\n",
      "Requirement already satisfied: google-api-core in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from google-generativeai) (2.25.1)\n",
      "Requirement already satisfied: google-api-python-client in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from google-generativeai) (2.175.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from google-generativeai) (2.40.3)\n",
      "Requirement already satisfied: protobuf in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from google-generativeai) (4.25.8)\n",
      "Requirement already satisfied: pydantic in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from google-generativeai) (2.11.7)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from google-generativeai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from google-generativeai) (4.14.1)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from google-api-core->google-generativeai) (1.70.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from google-api-core->google-generativeai) (2.32.5)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.73.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.62.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from google-auth>=2.15.0->google-generativeai) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.0.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2024.12.14)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from rsa<5,>=3.1.4->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
      "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pydantic->google-generativeai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pydantic->google-generativeai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pydantic->google-generativeai) (0.4.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install google-generativeai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7bc7955a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Config loaded\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# LangChain\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders.pdf import PDFPlumberLoader\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "# Google AI\n",
    "import google.generativeai as genai\n",
    "import os\n",
    "\n",
    "# ---------------- paths ----------------\n",
    "PDF_PATH        = Path(\"../Sources/book.pdf\")\n",
    "QUERIES_PATH    = Path(\"../Sources/queries.json\")\n",
    "SUBMISSION_CSV  = Path(\"./submission.csv\")\n",
    "\n",
    "PERSIST_DIR     = Path(\"./chroma_db\")\n",
    "COLLECTION_NAME = \"psychology_textbook\"\n",
    "\n",
    "# ---------------- RAG params ----------------\n",
    "CHUNK_SIZE      = 800   # ~200 tokens\n",
    "CHUNK_OVERLAP   = 100\n",
    "CANDIDATE_K     = 30\n",
    "FINAL_K         = 10\n",
    "\n",
    "EMBED_MODEL     = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "\n",
    "print(\"✅ Config loaded\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f007cbd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Gemini 2.5 Flash ready\n"
     ]
    }
   ],
   "source": [
    "# Set API key (paste your key here or set in environment before starting notebook)\n",
    "os.environ[\"GEMINI_API_KEY\"] = \"\"\n",
    "\n",
    "genai.configure(api_key=os.environ[\"GEMINI_API_KEY\"])\n",
    "gemini_model = genai.GenerativeModel(\"gemini-2.5-flash\")\n",
    "\n",
    "print(\"✅ Gemini 2.5 Flash ready\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "87c5caa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded 753 pages → 3387 chunks (all with page numbers)\n"
     ]
    }
   ],
   "source": [
    "# Load PDF\n",
    "loader = PDFPlumberLoader(str(PDF_PATH))\n",
    "docs = loader.load()\n",
    "\n",
    "# Ensure all docs have page numbers\n",
    "for i, doc in enumerate(docs, start=1):\n",
    "    if \"page\" not in doc.metadata or doc.metadata[\"page\"] is None:\n",
    "        doc.metadata[\"page\"] = i  # fallback: sequential page assignment\n",
    "\n",
    "# Split into chunks\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=CHUNK_SIZE,\n",
    "    chunk_overlap=CHUNK_OVERLAP\n",
    ")\n",
    "chunks = splitter.split_documents(docs)\n",
    "\n",
    "# Ensure each chunk inherits a valid page\n",
    "for chunk in chunks:\n",
    "    if \"page\" not in chunk.metadata or chunk.metadata[\"page\"] is None:\n",
    "        chunk.metadata[\"page\"] = chunk.metadata.get(\"source\", \"Unknown\")\n",
    "\n",
    "print(f\"✅ Loaded {len(docs)} pages → {len(chunks)} chunks (all with page numbers)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "386bdeb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Using existing Chroma DB\n"
     ]
    }
   ],
   "source": [
    "# Initialize embeddings\n",
    "embedding_fn = HuggingFaceEmbeddings(model_name=EMBED_MODEL)\n",
    "\n",
    "# Initialize Chroma vector DB\n",
    "vectordb = Chroma(\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    embedding_function=embedding_fn,\n",
    "    persist_directory=str(PERSIST_DIR)\n",
    ")\n",
    "\n",
    "# Add chunks if DB empty\n",
    "if vectordb._collection.count() == 0:\n",
    "    vectordb.add_documents(chunks)\n",
    "    print(\"✅ Chunks added to Chroma DB\")\n",
    "else:\n",
    "    print(\"✅ Using existing Chroma DB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f87e0800",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_context(question: str, k=CANDIDATE_K, final_k=FINAL_K):\n",
    "    retriever = vectordb.as_retriever(search_kwargs={\"k\": k})\n",
    "    candidates = retriever.invoke(question)   # new API (avoids deprecation warning)\n",
    "\n",
    "    # Collect only final_k with valid page numbers\n",
    "    selected = []\n",
    "    for doc in candidates:\n",
    "        if doc.metadata.get(\"page\") is not None:\n",
    "            selected.append(doc)\n",
    "        if len(selected) == final_k:\n",
    "            break\n",
    "\n",
    "    context = \"\\n\\n---\\n\\n\".join(doc.page_content for doc in selected)\n",
    "    pages = [doc.metadata[\"page\"] for doc in selected]\n",
    "\n",
    "    return selected, context, pages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "46854f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate.from_template(\n",
    "\"\"\"Answer the following question in an academic style using only the provided context. Don't give lengthy explanations. Keep it concise and to the point as per the context.\n",
    "Paraphrase instead of copying verbatim. Cite textbook pages at the end of the answer like [p. <number>]. Don't cite the pages in the middle of the answer. You don't have to consider the entire context. Just answer the question based on relevant information from the context. \n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9c7b59de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The scientific method in psychology is an empirical process used to advance scientific knowledge by studying the mind and behavior. This method relies on observation and experimentation, rather than solely on logical arguments or previous authorities. It operates as a circular process where ideas, in the form of theories and hypotheses, are tested against real-world empirical observations, which then lead to the development of further ideas. Both deductive and inductive reasoning are integral to this scientific process [p. 1, 8, 40].\n"
     ]
    }
   ],
   "source": [
    "def answer_question(question: str) -> dict:\n",
    "    docs, context, pages = prepare_context(question)\n",
    "    prompt_str = prompt.format(question=question, context=context)\n",
    "\n",
    "    # Call Gemini\n",
    "    response = gemini_model.generate_content(prompt_str)\n",
    "    answer = response.text.strip() if response and response.text else \"\"\n",
    "\n",
    "    return {\n",
    "        \"answer\": answer,\n",
    "        \"context\": context,\n",
    "        \"references\": {\"pages\": pages}\n",
    "    }\n",
    "\n",
    "# Quick test\n",
    "test_out = answer_question(\"What is the scientific method in psychology?\")\n",
    "print(test_out[\"answer\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "981ed729",
   "metadata": {},
   "source": [
    "**Installing Dependencies**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "9ac51acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q google-generativeai python-dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "0f52eee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os, json\n",
    "import pandas as pd\n",
    "from pydantic import BaseModel, Field\n",
    "import google.generativeai as genai\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "9ee236fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "LLM_NAME = \"gemini-1.5-flash\"\n",
    "load_dotenv()\n",
    "GEMINI_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "if not GEMINI_KEY:\n",
    "    raise RuntimeError(\"GEMINI_API_KEY missing in .env\")\n",
    "genai.configure(api_key=GEMINI_KEY)\n",
    "gemini_model = genai.GenerativeModel(LLM_NAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "2bac9142",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "PDF_PATH = Path(\"../../Sources/book.pdf\")\n",
    "loader = PyPDFLoader(str(PDF_PATH))\n",
    "pages = loader.load()\n",
    "\n",
    "CHUNK_SIZE = 1000\n",
    "CHUNK_OVERLAP = 200\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=CHUNK_SIZE,\n",
    "    chunk_overlap=CHUNK_OVERLAP\n",
    ")\n",
    "\n",
    "docs = splitter.split_documents(pages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "36a2dece",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "EMBED_MODEL = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "embeddings = HuggingFaceEmbeddings(model_name=EMBED_MODEL)\n",
    "PERSIST_DIR = Path(\"./chroma_store\")\n",
    "COLLECTION_NAME = \"textbook_chunks\"\n",
    "\n",
    "db = Chroma.from_documents(\n",
    "    documents=docs,\n",
    "    embedding=embeddings,\n",
    "    persist_directory=str(PERSIST_DIR),\n",
    "    collection_name=COLLECTION_NAME\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "0d030978",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "PAGE_TO_SECTION_PATH = Path(\"./helper/page_to_section.json\")\n",
    "with open(PAGE_TO_SECTION_PATH, \"r\") as f:\n",
    "    page_to_section = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "8fa228e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class QAResponse(BaseModel):\n",
    "    answer: str = Field(..., description=\"Answer in 100-300 words\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "fd30a559",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def prepare_context(query: str, k: int = 3):\n",
    "    \"\"\"\n",
    "    Retrieve top-k chunks for a given query,\n",
    "    adjust page numbers, and map them to sections.\n",
    "    \"\"\"\n",
    "    retriever = db.as_retriever(search_kwargs={\"k\": k})\n",
    "    results = retriever.invoke(query)\n",
    "\n",
    "    output = {\"question\": query}\n",
    "\n",
    "    for idx, doc in enumerate(results, start=1):\n",
    "\n",
    "    # 1. Get the page number from metadata\n",
    "      raw_page = doc.metadata.get(\"page_label\")\n",
    "\n",
    "    # If no page number is found, skip this chunk\n",
    "      if raw_page is None:\n",
    "          continue\n",
    "\n",
    "    # 2. Adjust the page number (remove front matter offset)\n",
    "      adjusted_page = int(raw_page) - 12\n",
    "      page_str = str(adjusted_page)\n",
    "\n",
    "    # 3. Find the textbook section for this page\n",
    "      section_name = page_to_section.get(page_str, \"Unknown_Section\")\n",
    "\n",
    "    # 4. Add this chunkâ€™s info into the output\n",
    "      output[f\"chunk{idx}\"] = [doc.page_content]   # the actual text\n",
    "      output[f\"page number {idx}\"] = [page_str]    # adjusted page number\n",
    "      output[f\"section {idx}\"] = [section_name]    # matching section\n",
    "\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "91e3716f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "PROMPT_TEMPLATE = (\n",
    "    \"You are a psychology tutor. Using ONLY the context, answer the question in atleast 50 words and atmost 400 words, not more than that.\"\n",
    "    \"If the context is insufficient, state what is missing.\\n\\n\"\n",
    "    \"Question: {question}\\n\\nContext:\\n{context}\\n\\n\"\n",
    "    \"Write only the answer. Do not include any citations, page numbers, or section names in the answer text.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "486d6a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def format_context_for_prompt(context_data):\n",
    "    \"\"\"Clean context string: only the text content (no section/page).\"\"\"\n",
    "    parts = []\n",
    "    i = 1\n",
    "    while f\"chunk{i}\" in context_data:\n",
    "        text = context_data[f\"chunk{i}\"][0]\n",
    "        parts.append(text)\n",
    "        i += 1\n",
    "    return \"\\n\\n\".join(parts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "933acbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def answer_question(question: str, k: int = 3):\n",
    "    \"\"\"Retrieve context, build prompt, and query Gemini with QAResponse schema.\"\"\"\n",
    "    context_data = prepare_context(question, k=k)\n",
    "    formatted_context = format_context_for_prompt(context_data)\n",
    "    prompt = PROMPT_TEMPLATE.format(question=question, context=formatted_context)\n",
    "\n",
    "    try:\n",
    "        response = gemini_model.generate_content(\n",
    "            prompt,\n",
    "            generation_config={\n",
    "                \"response_mime_type\": \"application/json\",\n",
    "                \"response_schema\": QAResponse\n",
    "            }\n",
    "        )\n",
    "        if hasattr(response, \"parsed\") and response.parsed:\n",
    "            answer_text = response.parsed.answer\n",
    "        else:\n",
    "            try:\n",
    "                data = json.loads(response.text)\n",
    "                answer_text = data.get(\"answer\", \"\")\n",
    "            except Exception:\n",
    "                answer_text = response.text or \"\"\n",
    "    except Exception as e:\n",
    "        answer_text = f\"Error: {str(e)}\"\n",
    "\n",
    "    sources = []\n",
    "    i = 1\n",
    "    while f\"chunk{i}\" in context_data:\n",
    "        sources.append({\n",
    "            \"chunk\": i,\n",
    "            \"page\": context_data.get(f\"page number {i}\", [\"?\"])[0],\n",
    "            \"section\": context_data.get(f\"section {i}\", [\"?\"])[0]\n",
    "        })\n",
    "        i += 1\n",
    "\n",
    "    return {\n",
    "        \"question\": question,\n",
    "        \"answer\": (answer_text or \"\").strip(),\n",
    "        \"sources_used\": sources\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "b8030b80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The scientific method in psychology involves testing ideas (theories and hypotheses) against real-world observations.  This process allows for the advancement of scientific knowledge within the field.  It is a cyclical process where observations lead to the formation of theories, which then generate testable hypotheses. The results of these tests inform whether the theory should be revised, refined, or rejected, leading to further testing and refinement of knowledge.  Essentially, it's a systematic approach to understanding behavior and mental processes through empirical evidence and rigorous testing.\n",
      "Sources:\n",
      "- psychological_research/why_is_research_important (p.39)\n",
      "- psychological_research/why_is_research_important (p.39)\n",
      "- psychological_research/why_is_research_important (p.39)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_q = \"What is the scientific method in psychology?\"\n",
    "res = answer_question(test_q, k=3)\n",
    "print(res[\"answer\"])\n",
    "print(\"Sources:\")\n",
    "for s in res[\"sources_used\"]:\n",
    "    print(f\"- {s['section']} (p.{s['page']})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "96772bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 50 questions\n",
      "Batch processor ready (competition format)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "QUERIES_PATH = Path(\"../../Sources/queries.json\")\n",
    "with open(QUERIES_PATH, \"r\") as f:\n",
    "    queries = json.load(f)\n",
    "\n",
    "print(f\"Loaded {len(queries)} questions\")\n",
    "\n",
    "def process_all_questions(queries_list, output_filename=\"submission_solution2.csv\", k=3):\n",
    "    rows = []\n",
    "    for q in queries_list:\n",
    "        # Get the full response with context data\n",
    "        context_data = prepare_context(q[\"question\"], k=k)\n",
    "        formatted_context = format_context_for_prompt(context_data)\n",
    "        \n",
    "        # Get the answer\n",
    "        r = answer_question(q[\"question\"], k=k)\n",
    "        \n",
    "        # Extract sections and pages for references\n",
    "        sections = []\n",
    "        pages = []\n",
    "        i = 1\n",
    "        while f\"chunk{i}\" in context_data:\n",
    "            page = context_data.get(f\"page number {i}\", [\"?\"])[0]\n",
    "            section = context_data.get(f\"section {i}\", [\"?\"])[0]\n",
    "            if page != \"?\" and page not in pages:\n",
    "                pages.append(page)\n",
    "            if section != \"?\" and section not in sections:\n",
    "                sections.append(section)\n",
    "            i += 1\n",
    "        \n",
    "        # Sort pages numerically\n",
    "        pages = sorted(pages, key=lambda x: int(x) if x.isdigit() else float('inf'))\n",
    "        \n",
    "        # Create references JSON\n",
    "        references = json.dumps({\n",
    "            \"sections\": sections,\n",
    "            \"pages\": pages\n",
    "        })\n",
    "        \n",
    "        rows.append({\n",
    "            \"ID\": q[\"query_id\"],\n",
    "            \"context\": formatted_context,\n",
    "            \"answer\": r[\"answer\"],\n",
    "            \"references\": references\n",
    "        })\n",
    "    \n",
    "    df = pd.DataFrame(rows)\n",
    "    df.to_csv(output_filename, index=False)\n",
    "    print(f\"Saved -> {output_filename} ({len(rows)} rows)\")\n",
    "    return df\n",
    "\n",
    "print(\"Batch processor ready (competition format)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "922eaddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved -> submission2.csv (50 rows)\n"
     ]
    }
   ],
   "source": [
    "results_df = process_all_questions(queries, \"submission2.csv\", k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4b4768",
   "metadata": {},
   "source": [
    "Here is the final submission.csv file [submission.csv](submission2.csv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
